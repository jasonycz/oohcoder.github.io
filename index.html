<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>OohCode | 好奇的码农~</title>

  
  <meta name="author" content="sean chen">
  

  

  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  

  <meta property="og:site_name" content="OohCode"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="OohCode" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">OohCode</a>
    </h1>
    <p class="site-description">好奇的码农~</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    
  <article>

  
    
    <h3 class="article-title"><a href="/2017/01/23/gc-base/"><span>垃圾回收基本算法</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/01/23/gc-base/" rel="bookmark">
        <time class="entry-date published" datetime="2017-01-23T06:24:36.000Z">
          2017-01-23
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <blockquote>
<p>本章介绍GC的基本算法:GC标记-清除法，引用计数法, GC复制算法。这三种我认为是GC的三个方向的基本思维。其他方法都是围绕这个些基本方法展开的。</p>
</blockquote>
<h2 id="GC标记-清除法">GC标记-清除法</h2><h3 id="基本方法">基本方法</h3><p>所谓的标记-清除法，依据其字面意思就是，先做标记，然后在清除。这个过程分为两个阶段，标记阶段就是把所有活动对象坐上标记，清除阶段就是把那些没有做标记的对象，也就是非活动对象回收的阶段。利用伪代码表示就是:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mark_sweep() &#123;</span><br><span class="line">    mark_phase()</span><br><span class="line">    sweep_phase()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>标记阶段: 这个阶段从<code>根</code>出发，利用深度优先遍历(不用广度优先是因为深度优先搜索比广度优先搜索更能压低内存使用量。), 对每个能到达的活动对象都坐上标记(用一个位来表示)。这个阶段所花费的时间与”活动对象的总数”成正比。标记阶段伪代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mark_phase() &#123;</span><br><span class="line">    <span class="comment">#遍历根节点, 进行标记</span></span><br><span class="line">    <span class="keyword">for</span>(r: $roots)</span><br><span class="line">        mark(*r)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#标记函数</span></span><br><span class="line">mark(obj) &#123;</span><br><span class="line">    <span class="keyword">if</span>(obj.mark == FALSE)</span><br><span class="line">        obj.mark = TRUE</span><br><span class="line">        <span class="comment">#深度优先遍历</span></span><br><span class="line">        <span class="keyword">for</span>(child : children(obj))</span><br><span class="line">            mark(*child)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>清除阶段: 清除阶段主要工作是通过遍历整个堆，把未被标记的对象(非活动对象)回收再利用。回收对象就是把对象作为分块，连接到被称为”空闲链表”的单向链表。之后进行分配时遍历空闲链表就可以找到分块了。两个相邻的分块如果地址是连续的，就会对其进行<strong>合并</strong>, 合并操作可以减少碎片的发生。清除阶段的伪代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sweep_phase() &#123;</span><br><span class="line">    sweeping = $heap_start</span><br><span class="line">    <span class="comment">#遍历堆</span></span><br><span class="line">    <span class="keyword">while</span>(sweeping &lt; $head_end)</span><br><span class="line">        <span class="keyword">if</span>(sweeping.mark == TRUE)</span><br><span class="line">            sweeping.mark == FALSE</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="comment">#放入空闲链表</span></span><br><span class="line">            <span class="keyword">if</span>(sweeping.mark == $free_list + $free_list.size)</span><br><span class="line">                <span class="comment">#合并</span></span><br><span class="line">                $free_list.size += sweeping.size</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                sweeping.next = $free_list</span><br><span class="line">                $free_list = sweeping</span><br><span class="line">            sweeping += sweeping.size</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>分配: 进行mutator申请分块时，搜索空闲链表并找到合适大小的分块，这个过程就叫做分配。找到合适的分块大小有三种策略:</p>
<ol>
<li>First-fit: 找到最初发现大于等于size的分块就立刻返回。考虑到分配所需的时间，标记清除法选择的就是这种方法。</li>
<li>Best-fit: 遍历空闲链表，找到大于等于size的最小分块返回。</li>
<li>Worst-fit: 找出最大的分块，把分块分割成size大小和剩余分块。<br>分配阶段的伪代码:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">new_obj(size) &#123;</span><br><span class="line">    chunk = pickup_chunk(size, $free_list)</span><br><span class="line">    <span class="keyword">if</span>(chunk != NULL)</span><br><span class="line">        <span class="keyword">return</span> chunk</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        allocation_fail()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h3 id="优点/缺点">优点/缺点</h3><ul>
<li>优点:<ol>
<li>实现简单</li>
<li>与保守式GC算法兼容: 保守式算法就是不知道对象是否是指针，所以移动对象会造成错误(后面会讲到), 而标记清除算法是不会移动对象的，所以是兼容的。</li>
</ol>
</li>
<li>缺点:<ol>
<li>碎片化: 由于非活动对象分布不均匀，容易照成堆内的内存空间碎片化，不利于mutator的执行。</li>
<li>分配速度: 由于分配时需要遍历空闲链表，查找速度取决于要分配的块和空闲链表的分布。后面要讲到的复制算法和标记-压缩算法由于分块是连续内存分布的，所以速度要快。</li>
<li>与写时复制技术不兼容： 因为每次GC都要修改活动对象的标记位，导致写操作的发生，从而产生复制。</li>
</ol>
</li>
</ul>
<h3 id="多个空闲链表">多个空闲链表</h3><p>为了提高<strong>分配速度</strong>，一个改进就是把分块按照大小分为多个空闲链表，这样在分配的时候就可以根据要分配的空间的大小去对应的空闲链表中寻找，大大减少了查找分块的时间。<br>下面是利用多个空闲链表的new_obj()函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">new_obj(size)&#123;</span><br><span class="line">    <span class="comment">#index 是一个要分配的字的大小</span></span><br><span class="line">    index = size / (WORD_LENGTH / BYTE_LENGTH)</span><br><span class="line">    <span class="comment">#空闲链表一共有101个，0-100都是按照字精确分配到对应的$free_list[index]中，</span></span><br><span class="line">    <span class="comment">#大于100的字都分配到$free_list[101]中</span></span><br><span class="line">    <span class="keyword">if</span>(index &lt;= <span class="number">100</span>)</span><br><span class="line">        <span class="keyword">if</span>($free_list[index] != NULL)</span><br><span class="line">            <span class="comment">#直接找到对应的空闲链表</span></span><br><span class="line">            chunk = $free_list[index]</span><br><span class="line">            $free_list[index] = $free_list[index].next</span><br><span class="line">            <span class="keyword">return</span> chunk</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        <span class="comment">#大于100的需要遍历$free_list[101]找到合适大小的块</span></span><br><span class="line">        chunk = pickup_chunk(size, $free_list[<span class="number">101</span>])</span><br><span class="line">        <span class="keyword">if</span>(chunk != NULL)</span><br><span class="line">            <span class="keyword">return</span> chunk</span><br><span class="line"></span><br><span class="line">    allocation_fail()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="BiBOP法">BiBOP法</h3><p>针对标记-清除算法的<strong>碎片化</strong>问题, 可以把堆先分割成大小固定的块，让每个块只能配置同样大小的对象，这就是BiBOP法。如果某个大小字的活动对象很少，其他的字活动对象很多的话，这种情况也不能提高堆的利用率，无法解决碎片化的问题。</p>
<h3 id="位图标记法">位图标记法</h3><p>上面还说道标记-清除法不能够与写时复制技术兼容是因为修改标记位会引起复制发生，为了解决这个问题，位图标记法采用只收集各个对象的标志位并表格化，不跟对象一起管理。也就是把对象和标记位进行了分离。这样做有两个好处:</p>
<ol>
<li>与写时复制技术兼容: 因为GC的时候改变了标记位也不会引起对象的复制, 而位图表格非常小，所以即使被复制也不会有什么大的影响。</li>
<li>清除操作更高效: 在遍历堆的时候不需要取消标志位，可以最后在位图表格中设置。</li>
</ol>
<h3 id="延迟清除法">延迟清除法</h3><p>延迟清除法(Lazy Sweep)是缩减因清除操作而导致的mutator最大暂停时间的方法。这个方法的伪代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">new_obj(size)&#123;</span><br><span class="line">    <span class="comment">#用延迟清除法找到对应的块</span></span><br><span class="line">    chunk = lazy_sweep(size)</span><br><span class="line">    <span class="keyword">if</span>(chunk != NULL)</span><br><span class="line">        <span class="keyword">return</span> chunk</span><br><span class="line">    <span class="comment">#没有找到合适的，进行一次标记操作</span></span><br><span class="line">    mark_phase()</span><br><span class="line">    <span class="comment">#再用延迟清除法找到对应的块 </span></span><br><span class="line">    chunk = lazy_sweep(size)</span><br><span class="line">    <span class="keyword">if</span>(chunk != NULL)</span><br><span class="line">        <span class="keyword">return</span> chunk</span><br><span class="line">     </span><br><span class="line">    allocation_fail()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">lazy_sweep(size)&#123;</span><br><span class="line">    <span class="keyword">while</span>($sweeping &lt; $head_end)</span><br><span class="line">        <span class="keyword">if</span>($sweeping.mark == TRUE)</span><br><span class="line">            $sweeping.mark == FALSE</span><br><span class="line">        <span class="comment">#找到和大小合适的块</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>($sweeping.size &gt; size)</span><br><span class="line">            chunk = $sweeping</span><br><span class="line">            $sweeping += $sweeping + $sweeping.size</span><br><span class="line">            <span class="keyword">return</span> chunk</span><br><span class="line">        <span class="comment">#没找到继续往下找</span></span><br><span class="line">        $sweeping += $sweeping + $sweeping.size</span><br><span class="line">    <span class="comment">#遍历完了也没找到，$sweeping置为从头开始</span></span><br><span class="line">    $sweeping = $heap_start</span><br><span class="line">    <span class="keyword">return</span> NULL</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里跟之前不同的是$sweeping是一个全局变量，每次执行lazy_sweep的时候都会从当前$sweeping的位置往后查找。如果第一次没有找到，第二次就会从头开始查找，如果第二次也没有查到，那就是没有可以分配的块了。一般情况下第一次查找范围变小了，mutator的执行时间就短了。但是有一个问题是就是当数据分配不均，比如说后面的都是活动对象，前面的都是空的，反而会增加mutator的时间。如何改善这个问题，后面会再说到。</p>
<h2 id="引用计数法">引用计数法</h2>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/gc/">gc</a>
    </span>
    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/01/22/gc/"><span>垃圾回收算法总结</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/01/22/gc/" rel="bookmark">
        <time class="entry-date published" datetime="2017-01-22T06:56:28.000Z">
          2017-01-22
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <blockquote>
<p>最近研读了《垃圾回收的算法与实现》这本书， 对来垃圾回收(<code>GC</code>)的来龙去脉及理论和实践有了一个概括性，深入性的了解，这里分多篇进行总结。首先本文先对GC的理论来一个总览性的回顾.</p>
</blockquote>
<h2 id="什么是垃圾回收">什么是垃圾回收</h2><p>我们知道一台服务器的内存是有限的，而程序的运行需要占用内存空间，一个程序内部可能有些内存空间使用后不再使用，这部分不再使用的内从空间就被视为<code>垃圾</code>。而GC就是要</p>
<ol>
<li>找到内存空间里的垃圾</li>
<li>回收垃圾，让程序员能够再次利用这部分空间</li>
</ol>
<p>如果没有GC的情况下需要程序员自己手动管理内存，例如C/C++等程序。这个过程将会非常麻烦，如果管理不当就会照成内存泄露引起系统崩溃，引发各种恶性bug和安全问题。有了GC就会省去很大一部分精力，降低了开发的难度。</p>
<h2 id="垃圾回收基本概念">垃圾回收基本概念</h2><p>要深入了解垃圾回收的理论知识，下面这些关键件信息比必要掌握:</p>
<ul>
<li>对象/头/域: 这里对象是由头(heder)和域(field)构成的。头是指保持对象本身信息的部分，主要包括<strong>对象的大小</strong>和<strong>对象的种类</strong>;域是对象使用者可以访问的部分，域的数据类型主要分为指针和非指针两种。</li>
<li>指针: GC根据对象的指针指向去搜寻其他对象，对于非指针不进行任何操作。</li>
<li>mutator: 程序运行过程中关系的改变，主要包括<strong>生成对象</strong>和<strong>更新指针</strong>等操作。</li>
<li>堆: 用于动态存放对象的内存空间。当mutator申请存放对象时，所需的内从空间就是从这个堆中被分配给mutator的。</li>
<li>活动对象/非活动对象: 内存空间中可以通过mutator引用的对象是”活动对象”, 不能通过程序引用的称为”非活动对象”。非活动对象无法重新被引用，所以就是”垃圾”。</li>
<li>分配: 内存空间中分配(allocatio)对象。当mutator需要新对象时，就会向分配器(allocator)申请一个大小合适的空间。</li>
<li>分块: 未利用对象而事先准备的空间。初始状态堆就是一个大分块，根据mutator的需求而分割成合适的大小。</li>
<li>根: 跟是指向对象的指针的起点，通过mutator可以直接调用的调用栈(call stack),寄存器和全局变量都是根。但是调用栈和寄存器中的值是不是指针，需要再做判断。</li>
<li>评价标准: GC算法的性能评价标准主要有<ol>
<li>吞吐量: 单位时间内的处理能力。</li>
<li>最大暂停时间: 因执行GC和停止mutator的最长时间。</li>
<li>堆使用效率</li>
<li>访问的局部性: 局部性原理，数据离得越近越好处理。</li>
</ol>
</li>
</ul>
<h2 id="垃圾回收算法总览">垃圾回收算法总览</h2><p>首先先上一张垃圾回收算法的总概括图:<br><img src="/assets/img/gc/GC.png" alt="垃圾回收算法总览"><br>上面列举和好多算法及对应的细节。其实GC最基本的思想就是三种算法(GC标记-清除法, 引用计数法, GC复制算法), 其他算法都算是这几个算法的延伸和组合。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/gc/">gc</a>
    </span>
    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2016/08/23/phpenv-configuration-options/"><span>phpenv安装自定义配置</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/08/23/phpenv-configuration-options/" rel="bookmark">
        <time class="entry-date published" datetime="2016-08-23T08:45:47.000Z">
          2016-08-23
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="自定义配置">自定义配置</h2><p>在使用phpenv安装php是，有时候需要对内置扩展进行自定义控制是否开启，比如我要开启<code>zts</code>模块, 源码安装我么可以用<code>./configure --enable-maintainer-zts</code>来安装，但是phpenv不支持直接这么写，这时候就要phpenv自己的方式来安装了。可以在phpenv安装的路径里找到下面这个文件：<code>~/.phpenv/plugins/php-build/bin/php-build</code>, 这个文件就是phpenv install时运行的脚本，可以找到如下内容:<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">CONFIGURE_OPTIONS=$(cat <span class="string">"$PHP_BUILD_ROOT/share/php-build/default_configure_options"</span>)</span><br><span class="line">...</span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"$PHP_BUILD_CONFIGURE_OPTS"</span> ]; then</span><br><span class="line">    CONFIGURE_OPTIONS=<span class="string">"$CONFIGURE_OPTIONS $PHP_BUILD_CONFIGURE_OPTS"</span></span><br><span class="line">fi</span><br><span class="line">...</span><br><span class="line">local append_default_libdir=<span class="string">'yes'</span></span><br><span class="line"><span class="keyword">for</span> option in <span class="variable">$CONFIGURE_OPTIONS</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="keyword">case</span> <span class="string">"$option"</span> in</span><br><span class="line">    <span class="string">"--with-libdir"</span>*) append_default_libdir=<span class="string">'no'</span> ;;</span><br><span class="line">  esac</span><br><span class="line">done</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"$(uname -p)"</span> = <span class="string">"x86_64"</span> ] &amp;&amp; [ <span class="string">"$&#123;append_default_libdir&#125;"</span> = <span class="string">'yes'</span> ]; then</span><br><span class="line">    argv=<span class="string">"$argv --with-libdir=lib64"</span></span><br><span class="line">fi</span><br><span class="line">...</span><br><span class="line">./configure <span class="variable">$argv</span> &gt; /dev/<span class="keyword">null</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>可见，默认会读取<code>~/.phpenv/plugins/php-build/share/php-build/default_configure_options</code>里面的配置加到<code>./configure</code>的参数里，当存在变量<code>$PHP_BUILD_CONFIGURE_OPTS</code>时，会把这个变量的值也加到<code>./configure</code>的参数里。<br>所以就存在两种方式实现上面的安装方法：</p>
<ol>
<li><code>~/.phpenv/plugins/php-build/share/php-build/default_configure_options</code>文件末尾加上<code>--enable-maintainer-zts</code></li>
<li>运行<code>PHP_BUILD_CONFIGURE_OPTS=--enable-maintainer-zts phpenv install 5.6.2</code></li>
</ol>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/php/">php</a>
    </span>
    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2015/10/14/InnoDB-Key-Features/"><span>InnoDB关键特性</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/14/InnoDB-Key-Features/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-14T14:10:14.000Z">
          2015-10-14
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <blockquote>
<p>本篇博客是《Mysql技术内幕 InnoDB存储引擎(第二版)》的阅读总结.</p>
</blockquote>
<h2 id="工作方式">工作方式</h2><p>首先Mysql进程模型是单进程多线程的。所以我们通过ps查找mysqld进程是只有一个。</p>
<h3 id="体系架构">体系架构</h3><p>InnoDB存储引擎的架构如下图所以，是由多个内存块组成的内存池，同时又多个后台线程进行工作，文件是存储磁盘上的数据。</p>
<img src="http://www.plantuml.com/plantuml/svg/AqfDBadCIyz9LNWshVt9xcqArLmAG92IM9AOb5YSgg044JPKWeZNOfKrmYkR1vUjvIg2M_UqhVNfsXbGwn32Iaydz3tjt_1yr_xdAxgLeD8Qled59Qb52Y4PHQc9APeGCKz_L7v1QL5wAgfGG29Gn3adDJ4FJNCjkgsUUNdvBav01prjMl5qpzHda_iWxdksSO4IqDdGiB7HjOEw6m00">  
<h4 id="后台线程">后台线程</h4><p>上面看到一共有四种后台线程，每种线程都在不停地做自己的工作，他们的分工如下:</p>
<ul>
<li><code>Master Thread</code>: 是最核心的线程，主要负责将缓冲池中的数据异步刷新的磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲(INSERT BUFFER),UNDO页的回收等。下面几个线程其实是为了分担主线程的压力而在最新的版本中添加的。</li>
<li><code>IO Thread</code>: InnoDB使用大量的异步IO来处理请求。IO Thread的主要工作就是负责IO请求的回调(call back)处理。异步IO可以分为4个，分别是:write, read, insert buffer 和 log IO thread。</li>
<li><code>Purge Thread</code>: undo log是用来保证事务的，当一个事务正常提交后，这个undo log可能就不再使用了。purge thread就是用来清除这部分log已经分配的undo页的。 </li>
<li><code>Page Cleaner Thread</code>: 主要是把脏页的刷新从主线程中拿到单独的线程，减轻主线程的压力，减少用户查询线程的阻塞，提高整体性能。</li>
</ul>
<h4 id="内存">内存</h4><p>由于InnoDB是基于磁盘存储的，为了使CPU与磁盘能够快的交互，提升整体性能而采用了缓冲池技术。<br>读数据简单的说可以用下面的流程图<br><img src="http://www.plantuml.com/plantuml/svg/Aov9B2hXidgnVlUpgHkUzQwpvifCKz20i9_EMV5yp-IdRPkURLoWgL2IaPgde56PMgp9fG04LY_sJtawUnvCLsfESQg2Hbu-LFB9xhxdYnkVpvu1DFXf_pIOAh2SafjdXDBJZWrmiwsn6fYNafd6LLoINm00"><br>更新数据的流程则如下:<br><img src="http://www.plantuml.com/plantuml/svg/Aov9B2hXidgnVlVJzbtFfcvurhlEcYilloHLeIWpFQF4Ik75_fdFfczxsZ0J8lbaHyFJTREUpbdnVC_afssRdcrSy6J7sYUxshYiditUycpQ1cJXvxDQO2PQFTkzyCMspS_cBdooUzlxFJrFExO35J-TFU_vuiRdisTOSnMNv1S00000"><br>由缓冲池的作用可以看到，缓冲池越大所容纳的数据就越多，与磁盘的交互就会越少，性能也就越高。所以缓冲池的大小直接影响着数据库的整体性能。<br>InnoDB在内存中主要有以下几部分组成:<br><img src="http://www.plantuml.com/plantuml/svg/TP31IiD048RlVOeX9tqDyU8x2CkskmcBszsoZI1AmGXfFLW4sneH15FiHQYrKg5AeI_ZnEOjZDbMH9CvVz_yCx_XDPygJtBOKqhlxc0xnF5DCdXEkayuULjDOpYfG3Rc1tJIJXU3soGQuJBwNFIm_GBx2hOCPngazaZrq7MvsNRWdpYymuVhTSJqFhT45ikgX38cVA4LbQJEwwIXjIHDSSmBjjZ8pD-uDYztCjoU-pr_HVjL6h_cmOpw51hKAuoO3N4ns912CNvKXYQNLnYEVjKWL9CR7yfBw0SVopW99ZajTUq0X79r0RdgFAQdP_ZUnzuvpY_iKKx9MpYEC9pRpMkcLMbz0G00"><br>具体来看缓冲池中缓存的数据页类型有:</p>
<ul>
<li><code>索引页</code>: 缓存数据表索引</li>
<li><code>数据页</code>: 缓存数据页，占缓冲池的绝大部分</li>
<li><code>undo页</code>: undo页是保存事务，为回滚做准备的。</li>
<li><code>插入缓冲(Insert buffer)</code>: 上面提到的插入数据时要先插入到缓存池中。</li>
<li><code>自适应哈希索引(adaptive hash index)</code>: 除了B+ Tree索引外，在缓冲池还会维护一个哈希索引，以便在缓冲池中快速找到数据页。</li>
<li><code>InnoDB存储的锁信息(lock info)</code>: </li>
<li><code>数据字典(data dictionary)</code>:<br>内存中除了缓冲池外外还有:</li>
<li><code>重做日志缓冲redo log</code>: 为了避免数据丢失的问题，当前数据库系统普遍采用了write ahead log策略，既当事务提交时先写重做日志，再修改写页。当由于发生宕机而导致数据丢失时，可以通过重做日志进行恢复。InnoDB先将重做日志放到这个缓冲区，然后按照一定的频率更新到重做日志文件中。重做日志一般在下列情况下会刷新内容到文件:<ul>
<li>Master Thread每一秒将重做日志缓冲刷新到重做日志文件</li>
<li>每个事务提交时会将重做日志缓冲刷新到重做日志文件</li>
<li>当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件</li>
</ul>
</li>
<li><code>额外内存池</code>: InnoDB存储引擎中，对内存的管理师通过一种称为内存堆的方式进行的，在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。</li>
</ul>
<p>缓冲池是一个很大的内存区域，InnoDB是如何对这些内存进行管理的呢。答案就使用LRU list。<br><a href="https://en.wikipedia.org/wiki/Page_replacement_algorithm#Variants_on_LRU" target="_blank" rel="external">LRU</a>(Latest Recent Used, 最近最少使用)算法默认的是最近使用的放到表头，最早使用的放到表尾，依次排列。当有LRU填满时有新的进来就把最早的淘汰掉。InnoDB则是在这个基础上进行了修改:</p>
<ol>
<li>最近使用的不放到表头，而是根据配置放到一定比例处，这个地方叫做midpoint, midpoint之前的成为new列表，之后的成为old列表。淘汰的同样是表尾的页。</li>
<li>为了保证new列表的不经常使用时能够淘汰，设置了一个超时时间:innodb_old_blocks_time，当数据在midpoint(我理解应该是在old列表中，不然这个点的页就一个，变化也比较频繁)的时间超过找个时间时就会被提升到表头，new列表的表尾页则被置换到old列表中。</li>
</ol>
<p>这么做的原因主要是因为常见的索引或数据的扫描操作会连续读取大量的页，甚至是全表扫描。如果采用原来的LRU算法就会更新全部的缓冲池，其他查询需要的热点数据就会被冲走，导致更多的磁盘读取操作，降低数据库的性能。<br>LRU是用来管理已经读取的页，当数据库启动时LRU是空列表,既只有表头，没有内容。这时页都放在Free List中。当需要有数据读写时要进行需要获取分页，这时要从Free List中删除分页，然后添加到LRU list中。到一定时间Free List中的分页就会被分配完毕，这时候就正常使用上面的LRU策略。<br>LRU列表中的页被修改后，称该页为脏页(dirty page),既缓冲池中的数据和磁盘上的数据产生了不一致，这时脏页会被加入到一个Flush 列表中(注意，同时存在两个列表中)。然后根据刷新的机制定时的刷新到磁盘中。</p>
<h3 id="Checkpoint技术">Checkpoint技术</h3><p>checkpoint其实就是一个刷新缓冲到磁盘的触发机制，当满足一定的条件时就会刷新缓冲到磁盘，这样做可以解决以下几个问题:</p>
<ul>
<li>缩短数据库的恢复时间: 数据库恢复可以使用redo log，但是如果要恢复的数据很多就会很慢。如果使用checkpoint刷新到磁盘，只需要从checkpoint开始恢复就可以了，所以速度会变快。</li>
<li>缓冲池不够用时，将脏页刷新到磁盘。我们知道缓冲池的大小是由限制的，为了能够高效的使用缓冲池需要把一部分数据刷新到磁盘。</li>
<li>重做日志不可用时，刷新脏页。重做日志并不是无限增大的，而是循环利用的。当有些已经不需要的页存在时可以覆盖写，当可用的页放不下时就会触发checkpoint,刷新到磁盘一部分脏页到磁盘，这样就能覆盖掉一些不再使用的重做日志。</li>
</ul>
<p>checkpoint根据触发时间，刷新页的策略又可以分为:</p>
<ul>
<li><code>sharp checkpoint</code>:刷新所有的脏页到磁盘。一般发生在数据库关闭时，为了保证所有的数据能够正常持久化。</li>
<li><code>fuzzy checkpoint</code>:只刷新部分脏页。运行时使用这种可以保证系统的性能。<h3 id="Master_Thread的工作方式">Master Thread的工作方式</h3></li>
</ul>
<h2 id="关键特性">关键特性</h2><h3 id="插入缓存">插入缓存</h3><p>这里所说的插入缓存也是Insert Buffer, 区别是这个插入缓存不是缓冲池中的插入缓存,这里的插入缓存和数据页一样，业务物理页的组成部分。在介绍插入缓存之前先了解<a href="http://www.cnblogs.com/lwzz/archive/2012/08/05/2620824.html" target="_blank" rel="external">聚集索引和非聚集索引</a>，他们之间最重要的区别就是:聚集索引的叶子节点存储的是数据，而且是按照物理顺序存储的;非聚集索引叶子节点是地址(也就是聚集索引键地址)，是按照逻辑顺序存储的(以上言论是从网上了解到的，但是本书P194特别指出，聚集索引也不是按照物理地址连续的，而是逻辑上连续的)。<br>知道这个差别后就知道，当不停的插入数据时，如果是聚集索引的数据，按照物理顺序(这个应该是一般情况下，因为是一般聚集索引是主键，顺序递增的，所以这时候地址就是顺序的)连续插入，代价比较小。而如果是非聚集索引的插入则物理地址是离散的，会导致很大的系统开销，所以对于非聚集索引InnoDB开创性设计了Insert Buffer。使用InnoDB的Insert Buffer需要以下两个条件:</p>
<ul>
<li>索引是辅助索引(非聚集索引 secondary index);</li>
<li>索引不是唯一(unique)的。</li>
</ul>
<p>Insert Buffer的使用流程是:<br><img src="http://www.plantuml.com/plantuml/svg/LKvB2e906DxFAMPfLz1TkuuHD98G5iwqQ5U14j6Bx06zo22em5wOA5YdyH_r5WtOfc_vlIah6mp9V3m5yyXx2xxs-EAk84t5KhRTfPrLjhOIxm3HF7DUi3abaGtMap_sSU0MCAiI7KijGWi82yY9Y8-EUPk2I8qIBEdrdyXd7q77GJiEBYMT4eFXObDLYG6tC7queb39ZN1TyQN_RvaEqey9_NF-1SO-k9Eqtqsw8Knw4FhS7iRlZTZKAvgAAAitlW00"><br>要求索引不是唯一的是因为如果索引是唯一的，那么每次更新都要坚持是不是已经存在，每次还是要访问数据页，这就失去了使用Insert Buffer的优势。<br>后面还提到了Update buffer以及Merge的过程和Insert Buffer的实现，这里就不再一一说了。</p>
<h3 id="两次写">两次写</h3><p>上面提到的Insert Buffer是提高了数据库的性能，doublewrite则是提高了数据库的可靠性。一个场景是当一个16k的数据页只写了一部分,比如4k,这时候突然断电，就会导致这个页的数据不全。所以就会导致这个页的数据丢失。我们知道重做日志是用来恢复数据的，但是重做日志记录的是对页的物理操作，如果这个页已经发生了损坏在对其进行重做是没有意义的。</p>
<blockquote>
<p>上面这段话，其实我并没有看懂，因为对页操作之前是先写重做日志的，当发生宕机时正在写数据页，证明这时候重做日志已经写完了。这时重做日志的记录的完整的，当用这个记录去恢复数据时，不管页是不是损坏，重做日志直接覆盖不就行了么？为什么不行呢？等到后面我更加深入的了解后再来补充。</p>
</blockquote>
<p>doublewrite有两部分组成，一部分是内存中的doublewrite buffer, 大小为2MB,另一部分是物理磁盘上共享表空间中连续的128个页，既两个区，大小同样为2MB<br>。对缓冲池的脏页进行刷新时，比不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer, 之后通过doublewrite buffer再分两次，每次1MB的写入共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题。完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中。</p>
<p>如果磁盘写入时发生崩溃，可以从共享表空间的doublewrite中找到副本，将其复制到表空间文件，再应用重做日志。</p>
<blockquote>
<p>这个地方也有一个疑问，当doublewrite写入的过程中发生了崩溃，这时候数据该怎么办呢？</p>
</blockquote>
<h3 id="自适应哈希索引">自适应哈希索引</h3><p>对于缓冲池中的页，为了能够快速的查找，InnoDB跟情况对其建立了一个hash index。这样对于等值查询就能够利用这个索引更加快速的查找，提高了查找的性能。</p>
<h3 id="异步IO">异步IO</h3><p>为了提高磁盘的操作性能，当前的数据库系统都采用异步IO的方式处理磁盘操作。用户可以在发出一个IO请求胡立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作完成，这就是AIO。<br>AIO的另一个优势是可以进行IO Merge操作，也就是将多个IO合并为1个IO, 这样可以提高IOPS的性能。</p>
<h3 id="刷新临近页">刷新临近页</h3><p>Flush Neighbor Page(刷新临近页)是当刷新一个脏页时，InnoDB会检测该页所在区的所有页，如果是脏页，那么一起进行刷新。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/mysql/">mysql</a>
    </span>
    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2015/10/09/apache-and-nginx/"><span>apache与nginx对比</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/09/apache-and-nginx/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-09T07:09:38.000Z">
          2015-10-09
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="apache工作原理">apache工作原理</h2><p>apache httpd通过模块化的设计来适应各种环境，模块化的使用使其变得功能强大而且灵活。最基本的web服务器功能也是通过可选择的多处理模块(MPM)，用来绑定到网络端口上，以及调度子程序处理请求。这样做可以带来两个重要的好处:</p>
<ul>
<li>Apache httpd 能更优雅，更高效率的支持不同的平台。尤其是 Apache httpd 的 Windows 版本现在更有效率了，因为 <a href="http://httpd.apache.org/docs/2.4/zh-cn/mod/mpm_winnt.html" target="_blank" rel="external">mpm_winnt</a> 能使用原生网络特性取代在 Apache httpd 1.3 中使用的 POSIX 层。它也可以扩展到其它平台 来使用专用的 MPM。</li>
<li>Apache httpd 能更好的为有特殊要求的站点定制。例如，要求 更高伸缩性的站点可以选择使用线程的 MPM，即 <a href="http://httpd.apache.org/docs/2.4/zh-cn/mod/worker.html" target="_blank" rel="external">worker</a> 或 <a href="http://httpd.apache.org/docs/2.4/zh-cn/mod/event.html" target="_blank" rel="external">event</a>； 需要可靠性或者与旧软件兼容的站点可以使用 <a href="http://httpd.apache.org/docs/2.4/zh-cn/mod/prefork.html" target="_blank" rel="external">prefork</a>。</li>
</ul>
<p>下面主要介绍常用的两个MPM工作原理。</p>
<h3 id="perfork">perfork</h3><p>一个单独的控制进程(父进程)负责产生子进程，这些子进程用于监听请求并作出应答。Apache总是试图保持一些备用的 (spare)或是空闲的子进程用于迎接即将到来的请求。这样客户端就无需在得到服务前等候子进程的产生。在Unix系统中，父进程通常以root身份运行以便邦定80端口(注意这里是先绑定再fork的，所以意味着所有的子进程都监听了80端口)，而 Apache产生的子进程通常以一个低特权的用户运行。User和Group指令用于配置子进程的低特权用户。运行子进程的用户必须要对他所服务的内容有读取的权限，但是对服务内容之外的其他资源必须拥有尽可能少的权限。<br>子进程的个数会随着请求量的大小动态调整。调整的策略与perfork的配置息息相关，httpd.conf的配置文件有以下配置:<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;IfModule prefork.c&gt;</span><br><span class="line">StartServers 5</span><br><span class="line">MinSpareServers 5</span><br><span class="line">MaxSpareServers 10</span><br><span class="line">MaxClients 150</span><br><span class="line">MaxRequestsPerChild 0</span><br><span class="line">&lt;/IfModule&gt;</span><br></pre></td></tr></table></figure></p>
<p>具体的流程这里直接copy<a href="http://blog.csdn.net/hguisu/article/details/7395181" target="_blank" rel="external">Apache运行机制剖析</a>这篇博文的介绍。</p>
<ol>
<li>控制进程先建立’StartServers’个子进程;</li>
<li>当空闲进程数小于MinSpareServers时，继续创建子进程，直到满足空闲进程数大于等于MinSpareServers;</li>
<li>当并发请求高时而空闲进程数小于MinSpareServers时会继续创建子进程，最多可以创建MaxClients个;</li>
<li>当并发高峰过去时，空闲进程的数量大于MaxSpareServers时会删除多余的子进程，直到剩MaxSpareServers为止;</li>
<li>当子进程处理的连接数超过MaxRequestsPerChild时，自动关闭，当MaxRequestsPerChild为0时这没有这个限制;</li>
</ol>
<p>对每个参数的介绍如下:</p>
<ul>
<li><code>StartServers</code> 指定服务器启动时建立的子进程数量。</li>
<li><code>MinSpareServers</code> 最小的空闲进程数。如果当前空闲进程数少于MinSpareServers时，Apache将以每秒一个的速度产生新的子进程。</li>
<li><code>MaxSpareServers</code> 最大的空闲进程数。如果空闲进程数大于这个值，Apache父进程会自动kill掉一些多余的子进程。</li>
<li><code>MaxRequestsPerChild</code> 每个子进程可处理的请求数。每个子进程处理完<code>MaxRequestsPerChild</code>后将自动销毁。0意味着用户销毁。销毁的好处有以下两个:<ul>
<li>可以防止意外的内存泄露</li>
<li>在服务器负载下降的时候会自动减少子进程数</li>
</ul>
</li>
<li><code>MaxClients</code> 设定Apache可以同时处理的请求，是对性能影响最大的参数。如果请求数达到这个限制，那么后来的请求就需要排队，直到某个请求处理完毕。</li>
</ul>
<h3 id="worker">worker</h3><p>每个进程能够拥有的线程数量是固定的。服务器会根据负载情况增加或减少进程数量。一个单独的控制进程(父进程)负责子进程的建立。每个子进程能够建立ThreadsPerChild数量的服务线程和一个监听线程，该监听线程监听接入请求并将其传递给服务线程处理和应答。Apache总是试图维持一个备用(spare)或是空闲的服务线程池。这样，客户端无须等待新线程或新进程的建立即可得到处理。在Unix中，为了能够绑定80端口，父进程一般都是以root身份启动，随后，Apache以较低权限的用户建立子进程和线程。User和Group指令用于配置Apache子进程的权限。虽然子进程必须对其提供的内容拥有读权限，但应该尽可能给予他较少的特权。另外，除非使用了suexec ，否则，这些指令配置的权限将被CGI脚本所继承。<br>  相对于prefork，worker是2.0 版中全新的支持多线程和多进程混合模型的MPM。由于使用线程来处理，所以可以处理相对海量的请求，而系统资源的开销要小于基于进程的服务器。但是，worker也使用了多进程，每个进程又生成多个线程，以获得基于进程服务器的稳定性。这种MPM的工作方式将是Apache 2.0的发展趋势。</p>
<p>http.conf中也有关于worker的配置项:<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;IfModule worker.c&gt;</span><br><span class="line">StartServers 3</span><br><span class="line">MaxClients 2000</span><br><span class="line">ServerLimit 25</span><br><span class="line">MinSpareThreads 50</span><br><span class="line">MaxSpareThreads 200</span><br><span class="line">ThreadLimit 200</span><br><span class="line">ThreadsPerChild 100</span><br><span class="line">MaxRequestsPerChild 0</span><br><span class="line">&lt;/IfModule&gt;</span><br></pre></td></tr></table></figure></p>
<p>由主控制进程生成“StartServers”个子进程，每个子进程中包含固定的ThreadsPerChild线程数，各个线程独立地处理请求。同样，为了不在请求到来时再生成线程，MinSpareThreads和MaxSpareThreads设置了最少和最多的空闲线程数；而MaxClients设置了所有子进程中的线程总数。如果现有子进程中的线程总数不能满足负载，控制进程将派生新的子进程。<br>参数介绍:<br><code>StartServer</code> 服务器启动时建立的子进程数。<br><code>ServerLimit</code> 服务器允许配置的进程数上限。这个指令和ThreadLimit结合使用配置了MaxClients最大允许配置的数值。<br><code>MinSpareThreads</code> 最小空闲线程数。这个MPM将基于整个服务器监控空闲线程数。如果服务器中的总线程数太少，子进程将产生新的空闲线程。<br><code>MaxSpareThreads</code> 最大空闲线程数。这个MPM将基于整个服务器监控空闲线程数。如果服务器总的线程数太多，子进程将kill掉多余的空闲线程。MaxSpareThreads的取值范围是有限制的。<br><code>ThreadLimit</code> 每个子进程可配置的线程数上限。这个指令配置了每个子进程可配置的线程数ThreadsPerChild上限。<br><code>ThreadsPerChild</code> 每个子进程建立的常驻的执行线程数。子进程在启动时建立这些线程后就不再建立新的线程了。<br><code>MaxRequestsPerChild</code> 每个子进程在其生存期间允许执行的最大请求数量。到达这个限制后子进程将会结束，如果为0则永不结束( 注意，对于KeepAlive链接，只有第一个请求会被计数)。这样做的好处是:</p>
<ul>
<li>能够防止内存泄露无限进行，从而耗尽内存。</li>
<li>給进程一个有限寿命，从而有助于当服务器负载减轻时减少活动进程的数量。</li>
</ul>
<h3 id="apache”惊群”现象与解决方案">apache”惊群”现象与解决方案</h3><p>无论是上面那个MPM被选择，都有一问题就是主进程先监听80端口，然后又fork出子进程。所以可以知道，fork出来的每个子进程都在监听80端口，如果这时候有请求过来就会出现所有的空闲进程都回来抢这个fd,也就是这些进程都被唤醒了，但是最终只有一个进程能够拿到这个fd进行处理，其他进程因为拿不到进程而再次进入休眠状态，这就是”惊群”现象。<br>apache的prefork模型下的处理方式如下如所示:<br><img src="http://dl.iteye.com/upload/attachment/385428/e0714d6e-1c19-3f2b-9f0a-0592eee7c3ec.png" alt=""><br>apache通过在每个accept()函数上 增加互斥锁和条件变量 来解决这个惊群问题。保证每个请求只会被一个线程刚好拿到，不会影响其他线程；<br>这里详细介绍下：条件变量与互斥锁不同，条件变量是用来等待而不是用来上锁的。条件变量用来自动阻塞一个线程，直到某特殊情况发生为止。通常条件变量和互斥锁同时使用；互斥锁提供互斥机制，条件变量提供信号机制；<br>那么apache是如何利用条件变量和互斥锁来解决每次只有一个空闲线程被唤醒，并且处于监听者角色呢？<br>每次一个新的客户请求过来，正在监听的线程与该请求建立连接，并变为worker工作者线程。让出监听者角色时它同时发送信号到条件变量，并释放锁。这样在空闲（idle)状态的一个线程将被唤醒并获得锁。<br>也就是说：条件变量保证了其他线程在等待条件变化期间处于睡眠；互斥锁保证一次只有一个线程被唤醒<br>这个是参考<a href="http://alicsd.iteye.com/blog/865531" target="_blank" rel="external">客户/服务器程序设计范式</a>来的，但是有一个明显的问题是prefork是多进程模型不是多线程模型，由于现在还没读过apache源码，姑且认为总体的流程和思想是对的。有机会再深入阅读回来补充。</p>
<h2 id="nginx工作原理">nginx工作原理</h2><p>nginx使用的是多进程模型，类似于apache的prefork，不同的是nginx的子进程个数是固定的。nginx的进程模型可以用下图来表示:<br><img src="http://tengine.taobao.org/book/_images/chapter-2-1.PNG" alt=""><br>可以看到nginx进程模型是由一个mater进程和多个worker进程组成的，master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。 worker进程则是来处理请求用的。</p>
<h3 id="异步非阻塞">异步非阻塞</h3><p>上面提到nginx的worker进程用来处理请求，而worker的个数是有限的，当并发高的时候nginx是如何应对的呢？这里不得不提到一个概念<code>异步非阻塞</code>(参考UNP卷一第三版P160页的介绍)关于这个过程<a href="http://tengine.taobao.org/book/chapter_02.html" target="_blank" rel="external">nginx平台初探</a>介绍的很好，直接COPY过来:</p>
<blockquote>
<p>为什么nginx可以采用异步非阻塞的方式来处理呢，或者异步非阻塞到底是怎么回事呢？我们先回到原点，看看一个请求的完整过程。首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。阻塞调用会进入内核等待，cpu就会让出去给别人用了，对单线程的worker来说，显然不合适，当网络事件越多时，大家都在等待呢，cpu空闲下来没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。所以，在nginx里面，最忌讳阻塞的系统调用了。不要阻塞，那就非阻塞喽。非阻塞就是，事件没有准备好，马上返回EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。所以，才会有了异步非阻塞的事件处理机制，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制正好解决了我们上面的两个问题，拿epoll为例(在后面的例子中，我们多以epoll为例子，以代表这一类函数)，当事件没准备好时，放到epoll里面，事件准备好了，我们就去读写，当读写返回EAGAIN时，我们将它再次加入到epoll里面。这样，只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 我之前有对连接数进行过测试，在24G内存的机器上，处理的并发请求数达到过200万。现在的网络服务器基本都采用这种方式，这也是nginx性能高效的主要原因。</p>
</blockquote>
<p>所以推荐设置worker的个数为cpu的核数，在这里就很容易理解了，更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，提供了cpu亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</p>
<h3 id="nginx”惊群”现象与解决方案">nginx”惊群”现象与解决方案</h3><p>worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。</p>
<p>因为这里主要是对比apache与nginx的原理的不同，所以更深入的探讨nginx这里先不做介绍更深入的探讨nginx这里先不做介绍，以后有机会学习nginx源码的时候再写。</p>
<h2 id="参考文献">参考文献</h2><p><a href="http://httpd.apache.org/docs/2.4/zh-cn/mpm.html" target="_blank" rel="external">多处理模块(MPM)</a><br><a href="http://blog.csdn.net/hguisu/article/details/7395181" target="_blank" rel="external">Apache运行机制剖析</a><br><a href="http://tengine.taobao.org/book/chapter_02.html" target="_blank" rel="external">nginx平台初探</a><br><a href="http://alicsd.iteye.com/blog/865531" target="_blank" rel="external">客户/服务器程序设计范式</a><br><a href="http://blog.csdn.net/russell_tao/article/details/7204260" target="_blank" rel="external">“惊群”，看看nginx是怎么解决它的</a><br><a href="http://blog.csdn.net/zbszhangbosen/article/details/7982402" target="_blank" rel="external">web服务器nginx和apache的对比分析</a></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/apache/">apache</a><a href="/tags/nginx/">nginx</a>
    </span>
    

    </div>

    
  </div>
</article>




<nav class="pagination">
  
  
  <a href="/page/2/" class="pagination-next">下一页</a>
  
</nav>
    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2017 sean chen
    
  </p>
</footer>
    
  </div>
</div>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>